{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97830b52",
   "metadata": {},
   "source": [
    "## NILC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5a177d",
   "metadata": {},
   "source": [
    "Conforme vimos no último notebook, as crônicas, contos e romances de Clarice Lispector tinham um problema fundamental: o pequeno tamanho da amostra, que gerava resultados pouco satisfatórios. Pensando nisso, vamos usar arquivos do repositório do Núcleo Interinstitucional de Linguística Computacional (NILC), mais especificamente o *Continuous Bag of Words* para 50 e 300 dimensões (a ideia inicial era testar também com 1000 dimensões, mas a falta de espaço de armazenamento do meu computador não permitiu).\n",
    "\n",
    "A ideia, então, é repetir os processos usados no primeiro notebook, comparar os resultados obtidos no NILC com aqueles obtidos no córpus de textos de Lispector, e, por fim, discutir as diferenças no uso de 50 e 300 dimensões."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6dec58",
   "metadata": {},
   "source": [
    "### Parte 1: importação de bibliotecas e abertura de arquivos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7445dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4feaec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model_50 = KeyedVectors.load_word2vec_format('cbow_s50.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e90b1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_300 = KeyedVectors.load_word2vec_format('cbow_s300.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506851b0",
   "metadata": {},
   "source": [
    "### Parte 2: Similaridade de duas palavras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9db083e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82511467"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50.similarity(\"mulher\", \"pessoa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c489c4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.535594"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_300.similarity(\"mulher\", \"pessoa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cf0ded",
   "metadata": {},
   "source": [
    "**Conclusão Parte 2:** tanto o modelo com 50 dimensões quanto o modelo com 300 dimensões apresentaram similaridade entre \"mulher\" e \"pessoa\" menor do que aquela encontrada no córpus de textos de Lispector, o que é positivo, já que, apesar de terem semelhanças (uma mulher é uma pessoa), as palavras não são extremamente próximas, dado que a mulher não é o único tipo de pessoa. Sendo assim, o modelo com 300 dimensões parece ser o mais adequado nesse caso específico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35fbcda",
   "metadata": {},
   "source": [
    "### Parte 3: Top10 Palavras mais similares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60981cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pajem', 0.893057107925415),\n",
       " ('sacristão', 0.8862901329994202),\n",
       " ('mancebo', 0.8632415533065796),\n",
       " ('velhinho', 0.8508946895599365),\n",
       " ('vendeiro', 0.8465736508369446),\n",
       " ('lavrador', 0.8447821736335754),\n",
       " ('guarda-livros', 0.8393514752388),\n",
       " ('cavalheiro', 0.837705671787262),\n",
       " ('barbeiro', 0.8346974849700928),\n",
       " ('tratante', 0.8326072692871094)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50.most_similar(positive=\"moço\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87ea2a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mancebo', 0.7390948534011841),\n",
       " ('cavalheiro', 0.6541756987571716),\n",
       " ('pajem', 0.6214371919631958),\n",
       " ('barrolo', 0.6020280122756958),\n",
       " ('desgraçado', 0.6006842255592346),\n",
       " ('rapazola', 0.5986061096191406),\n",
       " ('rapazinho', 0.5898251533508301),\n",
       " ('rapaz', 0.5894635319709778),\n",
       " ('vendeiro', 0.578624427318573),\n",
       " ('cocheiro', 0.5681120753288269)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_300.most_similar(positive=\"moço\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd0e2609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hitória', 0.9151827692985535),\n",
       " ('trama', 0.884054958820343),\n",
       " ('historia', 0.8835107684135437),\n",
       " ('obra', 0.8813790082931519),\n",
       " ('recriação', 0.873521625995636),\n",
       " ('trilogia', 0.8733588457107544),\n",
       " ('epopéia', 0.8704574704170227),\n",
       " ('contemporaneidade', 0.8695754408836365),\n",
       " ('banda-sonora', 0.8661443591117859),\n",
       " ('literalidade', 0.8648191690444946)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50.most_similar(positive=\"história\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6caa4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('historia', 0.723188042640686),\n",
       " ('estória', 0.6907320022583008),\n",
       " ('his-tória', 0.6329914927482605),\n",
       " ('narrativa', 0.6301185488700867),\n",
       " ('trama', 0.6181331276893616),\n",
       " ('hitória', 0.6140969395637512),\n",
       " ('civilisação', 0.5994098782539368),\n",
       " ('histã³ria', 0.59772789478302),\n",
       " ('literalidade', 0.5941398739814758),\n",
       " ('fábula', 0.5935908555984497)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_300.most_similar(positive=\"história\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf6f79",
   "metadata": {},
   "source": [
    "**Conclusão Parte 3:** para o termo \"moço\", o modelo com 50 dimensões é menos genérico que o modelo do córpus de Clarice, mas ainda assim é falho, dado que apresenta profissões típicas de moços ao invés de sinônimos da palavra, como ocorre no modelo de 300 dimensões, com termos como \"rapazola\", \"rapazinho\" e \"rapaz\". Já o termo \"história\" apresenta palvras bastante similares e adequadas em ambos os modelos, como \"narrativa\", \"trama\" e \"obra\", representando um avanço em relação ao resultado do primeiro notebook. Todavia, há alguns erros gramaticais e de formatação na palavra \"história\" que aparecem como sinônimos do termo, como \"historia\", \"his-tória\" e \"hitória\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7959c3",
   "metadata": {},
   "source": [
    "### Parte 4: Patinho Feio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0176f766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'olho'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50.doesnt_match(['cabeça', 'olho', 'cama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66f05cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'olho'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_300.doesnt_match(['cabeça', 'olho', 'cama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac842107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pé'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50.doesnt_match(['dinheiro', 'poder', 'pé'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e7b0be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pé'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_300.doesnt_match(['dinheiro', 'poder', 'pé'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db0c72",
   "metadata": {},
   "source": [
    "**Conclusão Parte 4:** na parte 4, os dois modelos fizeram julgamentos idênticos: que \"cama\" e \"cabeça\" são mais próximos do que \"cabeça\" e \"olho\", o que é questionável, dado que o olho está na cabeça e ambos são partes do corpo humano, e que \"pé\" é o patinho feio em relação a \"dinheiro\" e \"poder\", o que era o resultado esperado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585e1e18",
   "metadata": {},
   "source": [
    "### Parte 5: Positivo x Negativo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "057129e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('czarina', 0.8199825286865234),\n",
       " ('princesa', 0.8150826692581177),\n",
       " ('imperatriz', 0.7842182517051697),\n",
       " ('infanta', 0.7797107100486755),\n",
       " ('deusa', 0.7794512510299683),\n",
       " ('raínha', 0.7770389318466187),\n",
       " ('grã-duquesa', 0.7733810544013977),\n",
       " ('arquiduquesa', 0.7628461718559265),\n",
       " ('imperatriz-mãe', 0.7618402242660522),\n",
       " ('matriarca', 0.7592216730117798)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50.most_similar(positive = [\"rei\", \"rainha\"], negative = [\"príncipe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2878ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('infanta', 0.5017511248588562),\n",
       " ('ex-rainha', 0.4902370572090149),\n",
       " ('raínha', 0.4754871129989624),\n",
       " ('rainha-mãe', 0.4736950993537903),\n",
       " ('princesa', 0.4433686137199402),\n",
       " ('rainha-consorte', 0.4423251450061798),\n",
       " ('imperatriz', 0.4362345039844513),\n",
       " ('czarina', 0.4306214451789856),\n",
       " ('condessa', 0.4092569947242737),\n",
       " ('rainha-viúva', 0.40874388813972473)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_300.most_similar(positive = [\"rei\", \"rainha\"], negative = [\"príncipe\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aaaa8d",
   "metadata": {},
   "source": [
    "**Conclusão Parte 5:** a parte 5, específica dos modelos do NILC (não está presente no modelo de Lispector), apresenta resultados satisfatórios - como os valores positivos eram \"rei\" e \"rainha\" e o negativo \"príncipe\", o esperado era que \"princesa\" e sinônimos dessa palavra ocupassem as primeiras posições do ranking, o que ocorre com a presença de termos como \"infanta\" e \"condessa\". Porém, alguns termos que dizem respeito a \"rainha\" também se fazem presentes, como \"imperatriz\", \"rainha-viúva\", \"czarina\", \"rainha-mãe\", etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f6f0a5",
   "metadata": {},
   "source": [
    "### Conclusão Word Embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8124763",
   "metadata": {},
   "source": [
    "Conforme vimos neste notebook, boa parte dos problemas do modelo que usou o córpus dos textos de Lispector foi solucionada, com o nível de precisão aumentando para números de dimensões maiores (e consequentemente arquivos de tamanhos maiores)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e652555c",
   "metadata": {},
   "source": [
    "## Sentence Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5941f",
   "metadata": {},
   "source": [
    "Como não há especificação do dataset a ser utilizado, optei por criar um doc com uma lista de frases famosas ditas por ex-presidentes do Brasil e compará-las com uma frase de Mandela acerca de respeito, preconceitos e democracia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c133f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas\n",
    "import nltk\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Dataset\n",
    "doc = [\"Lamento a campanha absolutamente difamatória que fazem contra mim, dizendo que estou utilizando o nome de Cristo para falar que nem ele me derrotava na eleição. Eu acho isso um absurdo, uma calúnia e uma vilania contra mim. Como vocês sabem que sou cristã, eu jamais usaria o nome de Cristo em vão!\",\n",
    "        \"A esquerda é boa para duas coisas: organizar manifestações de rua e desorganizar a economia\",\n",
    "        \"No Maranhão, depois dos 50 anos, não se pergunta a alguém como está de saúde. Pergunta-se onde é que dói. Realmente, estamos importando alimentos, mas isso é ótimo, porque significa que quem não comia está comendo.\",\n",
    "        \"Isso é outra coisa que precisa acabar no Brasil, essa mentalidade atrasada de que o presidente vai passear. Tenha paciência.\",\n",
    "        \"Uma coisa que nunca entendi é porque todo artista, esse tal de Caetano Veloso por exemplo, tem de ser dessa tal de esquerda.\",\n",
    "        \"Sou apenas um menino do Maranhão que o destino disse: vai José, ser Presidente!\",\n",
    "        \"Quando acontece alguma coisa errada no meu governo, eu fico triste.\",\n",
    "        \"A única solução é dar um tiro no coco. (Quando perguntado sobre o que faria se recebesse um salário mínimo).\",\n",
    "        \"O presidente Lula me deixou um legado, que é cuidar do povo brasileiro. Eu vou ser a mãe do povo brasileiro.\",\n",
    "        \"Saio da vida para entrar na história.\"\n",
    "        \"Mais que curso de doutor, as pessoas precisam fazer curso de inteligência e de sensibilidade para poderem dirigir seus países.\",\n",
    "        \"Creio na vitória final e inexorável do Brasil, como nação.\",\n",
    "        \"Eu não tenho a mesma posição histórica do presidente Collor. Agora, se ele quiser apoiar minha candidatura, é um problema da liberdade democrática...\",\n",
    "        \"Precisamos vencer a fome, a miséria e a exclusão social. Nossa guerra não é para matar ninguém - é para salvar vidas!\",\n",
    "        \"Não aceito propaganda de opções sexuais\",\n",
    "        \"Estou de saco cheio de ver companheiro acusado, humilhado, e depois não se provar nada contra ele.\",\n",
    "        \"Na primeira vez que me perguntaram se eu era comunista, respondi: 'Sou torneiro mecânico'.\",\n",
    "        \"Não tenho nenhuma outra expectativa a não ser terminar meu mandato, poder andar pelas ruas deste país afora, e que as pessoas digam: 'Lá vai o Collor, ele fez um bom governo.'\",\n",
    "        \"Cada um tem que inventar sua resposta. Dar sentido a sua vida. A vida, em si, não tem sentido. Cada um tem que construir o seu sentido. E vai sofrer para encontrar.\",\n",
    "        \"O meu primeiro ato como presidente será mandar para a cadeia um bocado de corruptos.\",\n",
    "        \"É muita pretensão do homem inventar que Deus o criou à sua imagem e semelhança. Será possível que Deus seja tão ruim assim? Eu sou um sujeito profundamente democrático.\",\n",
    "        \"Questionam o meu otimismo, mas sou católico, brasileiro, corintiano e ainda sou presidente do meu país, como poderia deixar de ser otimista.\",\n",
    "        \"Um governo forte se faz perdoando.\"\n",
    "        \"Quanto menos alguém entende, mais quer discordar...\",\n",
    "        \"Não é a moeda forte que faz o país. O país é que faz a moeda forte!\"]\n",
    "\n",
    "# Tokenização\n",
    "tokenized_doc = []\n",
    "for d in doc:\n",
    "    tokenized_doc.append(word_tokenize(d.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71a8e77",
   "metadata": {},
   "source": [
    "### Definição dos parâmetros e criação do modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3534894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_doc)]\n",
    "model = Doc2Vec(tagged_data, vector_size=20, window=2, min_count=2, workers=4, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9aa8acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"test_doc2vec.model\")\n",
    "model= Doc2Vec.load(\"test_doc2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b8228",
   "metadata": {},
   "source": [
    "### Teste do Modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e21f78c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-73-9620f66f1f21>:2: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  model.docvecs.most_similar(positive=[model.infer_vector(test_doc)],topn=5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.8816112875938416),\n",
       " (17, 0.8649958968162537),\n",
       " (11, 0.8280543684959412),\n",
       " (16, 0.818700909614563),\n",
       " (19, 0.7940447926521301)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doc = word_tokenize(\"Ninguém nasce odiando outra pessoa pela cor de sua pele, por sua origem ou ainda por sua religião. Para odiar, as pessoas precisam aprender, e se podem aprender a odiar, elas podem ser ensinadas a amar.\".lower())\n",
    "model.docvecs.most_similar(positive=[model.infer_vector(test_doc)],topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aef7783",
   "metadata": {},
   "source": [
    "**Autora da frase 0:** Dilma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "423d0486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument<['lamento', 'a', 'campanha', 'absolutamente', 'difamatória', 'que', 'fazem', 'contra', 'mim', ',', 'dizendo', 'que', 'estou', 'utilizando', 'o', 'nome', 'de', 'cristo', 'para', 'falar', 'que', 'nem', 'ele', 'me', 'derrotava', 'na', 'eleição', '.', 'eu', 'acho', 'isso', 'um', 'absurdo', ',', 'uma', 'calúnia', 'e', 'uma', 'vilania', 'contra', 'mim', '.', 'como', 'vocês', 'sabem', 'que', 'sou', 'cristã', ',', 'eu', 'jamais', 'usaria', 'o', 'nome', 'de', 'cristo', 'em', 'vão', '!'], [0]>\n"
     ]
    }
   ],
   "source": [
    "print(tagged_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c40d4",
   "metadata": {},
   "source": [
    "**Autor da frase 17:** FHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "357a24f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument<['cada', 'um', 'tem', 'que', 'inventar', 'sua', 'resposta', '.', 'dar', 'sentido', 'a', 'sua', 'vida', '.', 'a', 'vida', ',', 'em', 'si', ',', 'não', 'tem', 'sentido', '.', 'cada', 'um', 'tem', 'que', 'construir', 'o', 'seu', 'sentido', '.', 'e', 'vai', 'sofrer', 'para', 'encontrar', '.'], [17]>\n"
     ]
    }
   ],
   "source": [
    "print(tagged_data[17])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac642a9",
   "metadata": {},
   "source": [
    "**Autora da frase 11:** Dilma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d59f7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument<['eu', 'não', 'tenho', 'a', 'mesma', 'posição', 'histórica', 'do', 'presidente', 'collor', '.', 'agora', ',', 'se', 'ele', 'quiser', 'apoiar', 'minha', 'candidatura', ',', 'é', 'um', 'problema', 'da', 'liberdade', 'democrática', '...'], [11]>\n"
     ]
    }
   ],
   "source": [
    "print(tagged_data[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b7fe68",
   "metadata": {},
   "source": [
    "**Conclusões acerca do modelo**: a frase de Mandela tem como principal mensagem a superação de preconceitos. Sendo assim, é natural que as três frases mais similares à de Mandela sejam frases que abordem temas como a liberdade democrática, o sentido da vida e o preconceito religioso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
